{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slurp(path):\n",
    "    try:\n",
    "        with open(path, 'r') as fo:\n",
    "            text = fo.read()\n",
    "    except UnicodeDecodeError:\n",
    "        print(path)\n",
    "        with open(path, 'r', encoding='cp1252') as fo:\n",
    "            text = fo.read()\n",
    "    return text\n",
    "\n",
    "def spit(texts, file_names):\n",
    "    for text, file_name in tqdm(zip(texts, file_names)):\n",
    "        with open(file_name, 'w') as fo:\n",
    "            fo.write(text)\n",
    "\n",
    "def read_dir(input_path):\n",
    "    texts = []\n",
    "    files = []\n",
    "    print('Reading files...')\n",
    "    for root, dirs, filenames in os.walk(input_path):\n",
    "        files.extend(filenames)\n",
    "        for filename in tqdm(filenames):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            if '.ipynb' not in file_path:\n",
    "                text = slurp(file_path)\n",
    "                texts.append(text)\n",
    "    print('Number of texts: ', len(texts))\n",
    "    return texts, files\n",
    "\n",
    "def preprocess(input_path, output_path):\n",
    "    texts, filenames = read_dir(input_path)\n",
    "    pattern = re.compile(r'[А-ЯЁа-яё\\.\\-\\d]+')\n",
    "    preprocessed = []\n",
    "    print('Preprocessing files...')\n",
    "    for text in tqdm(texts):\n",
    "        preproc_text = ' '.join(re.findall(pattern, text))\n",
    "        preprocessed.append(preproc_text)\n",
    "    paths = [output_path + name for name in filenames if 'ipynb' not in name]\n",
    "    print('Number of texts: ', len(texts))\n",
    "    print('Number of paths:', len(paths))\n",
    "    print('Writing to files...')\n",
    "    spit(preprocessed, paths)\n",
    "    print('All done, Buddy!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess texts before parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spit_dir = '/home/nst/mount/data/linguistics_hse/popular-science-research/Tomita_Parser/tomita-parser/build/bin/sci_corpus/'\n",
    "slurp_dir = '/home/nst/mount/data/share/yd/popular_science_texts_store_copy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 0/707 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 6/707 [00:00<00:12, 54.75it/s]\u001b[A\n",
      "  2%|▏         | 14/707 [00:00<00:11, 61.65it/s]\u001b[A\n",
      "  3%|▎         | 20/707 [00:00<00:11, 59.24it/s]\u001b[A\n",
      "  4%|▍         | 29/707 [00:00<00:10, 65.30it/s]\u001b[A\n",
      "  5%|▌         | 38/707 [00:00<00:10, 64.70it/s]\u001b[A\n",
      "  7%|▋         | 47/707 [00:00<00:09, 68.41it/s]\u001b[A\n",
      "  8%|▊         | 57/707 [00:00<00:09, 71.64it/s]\u001b[A\n",
      "  9%|▉         | 65/707 [00:00<00:08, 72.38it/s]\u001b[A\n",
      " 10%|█         | 73/707 [00:01<00:08, 72.22it/s]\u001b[A\n",
      " 11%|█▏        | 81/707 [00:01<00:08, 71.68it/s]\u001b[A\n",
      " 13%|█▎        | 90/707 [00:01<00:08, 73.06it/s]\u001b[A\n",
      " 14%|█▍        | 98/707 [00:01<00:08, 72.23it/s]\u001b[A\n",
      " 15%|█▌        | 108/707 [00:01<00:08, 74.06it/s]\u001b[A\n",
      " 17%|█▋        | 117/707 [00:01<00:07, 74.23it/s]Exception in thread Thread-131:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nst/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/nst/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/nst/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 707/707 [00:09<00:00, 73.75it/s]\n",
      "100%|██████████| 1500/1500 [00:29<00:00, 50.77it/s]\n",
      "100%|██████████| 5166/5166 [00:58<00:00, 87.77it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1454/1454 [00:15<00:00, 96.60it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 600/600 [00:13<00:00, 44.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5005.14it/s]\n",
      "100%|██████████| 542/542 [00:11<00:00, 46.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\n",
      "100%|██████████| 11171/11171 [03:56<00:00, 47.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2452.81it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1413/1413 [00:20<00:00, 70.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6765.01it/s]\n",
      "100%|██████████| 3850/3850 [00:58<00:00, 65.50it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 562/562 [00:09<00:00, 60.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.60it/s]\n",
      "100%|██████████| 499/499 [00:12<00:00, 41.10it/s]\n",
      "100%|██████████| 499/499 [00:14<00:00, 33.85it/s]\n",
      "100%|██████████| 500/500 [00:10<00:00, 49.37it/s]\n",
      "100%|██████████| 500/500 [00:07<00:00, 67.47it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 99.52it/s] \n",
      "100%|██████████| 500/500 [00:07<00:00, 66.54it/s]\n",
      "100%|██████████| 500/500 [00:12<00:00, 39.50it/s]\n",
      "100%|██████████| 500/500 [00:08<00:00, 58.74it/s]\n",
      "100%|██████████| 89/89 [00:01<00:00, 76.92it/s]\n",
      "  0%|          | 67/31052 [00:00<00:46, 668.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts:  31052\n",
      "Preprocessing files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31052/31052 [00:13<00:00, 2247.23it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts:  31052\n",
      "Number of paths: 31052\n",
      "Writing to files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31052it [06:37, 78.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done, Buddy!\n"
     ]
    }
   ],
   "source": [
    "chrdk = preprocess(slurp_dir, spit_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch on test sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = '/home/nst/mount/data/share/yd/popular_science_texts_store/ner_markup/final_markup/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 1236.56it/s]\n"
     ]
    }
   ],
   "source": [
    "marked = []\n",
    "for root, dirs, filenames in os.walk(test_input):\n",
    "    for filename in tqdm(filenames):\n",
    "        path = test_input + filename\n",
    "        text = slurp(path)\n",
    "        marked.append(text)\n",
    "marked = list(set(marked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Крысы в штанах, независимые камни и человек-козел стали героями двадцать шестой Шнобелевской премии. О том, какие еще исследования были отмечены наградой, рассказывает Indicator.Ru.\\nМеждународная премия за научные достижения обошла вниманием российских исследователей. &Может!&, это и к лучшему, ведь речь идет о «Шнобелевке». В театре Сандерс при Гарвардском университете прошла церемония вручения двадцать шестой Шнобелевской премии – 26th Ig Nobel Prize. Название премии построено на игре слов: \"ignoble\" переводится с английского языка как «позорный». «Антинобелевскую» премию ежегодно вручают за научные исследования, которые «заставляют сначала посмеяться, а после задуматься».\\nКаждый год «Шнобеля» вручают нобелевские лауреаты. В этот раз организаторы пригласили &Дадли Хершбаха!& (химия, 1986), &Эрика Маскина!& (экономика, 2007), &Ричарда Робертса!& (физиология и медицина, 1993) и &Роя Глаубера!& (физика, 2005). \\nЧтобы получить награды за сомнительные научные достижения, лауреатам пришлось раскошелиться: в Гарвард они прибывали за свой счет. Но это точно того стоило: в начале церемонии состоялась премьера трехактной мини-оперы «Последняя секунда». По сюжету оперы кто-то запланировал тайно увеличить продолжительность суток на одну секунду, чтобы таким образом заставить людей работать дольше и увеличить свой достаток. \\nМышки в штанишках\\nПремию в области репродуктологии присудили ученому из Египта &Ахмеду Шафику!&. Жюри отметили сразу две его работы. &Шафик!& исследовал, как ношение брюк из разных тканей – натуральных (хлопка и шерсти) и синтетических (полиэстера) – сказывается на сексуальной активности крыс. Ученый надел штанишки на 75 животных и в течение года наблюдал за тем, как меняется их сексуальная жизнь. Исследователь анализировал данные, полученные после шести и 12 месяцев ношения крысами брюк. В результате больше всего пострадали животные, ходившие в штанишках из полиэстера. Их сексуальную активность, как считает ученые, снизило мощное статическое электричество, возникавшее от трения кусочков этой ткани.\\nМышь в штанахneatorama.com Получив результаты экспериментов с животными, &Шафик!& стал проводить исследования на мужчинах. Ученый собрал группу из 14 добровольцев без патологий в возрасте от 32 до 47 лет и предложил им обернуть мошонку полиэстеровой тканью на 12 месяцев. Манипуляции были необходимы для того, чтобы определить эффективность такого метода контрацепции. Испытуемым разрешалось менять ткань по мере ее загрязнения. &Шафик!& осматривал мужчин каждые две недели. Ношение ткани спровоцировало у мужчин азооспермию (отсутствие сперматозоидов), что подтвердило гипотезы о контрацептивном методе.\\nКаменные и гламурные\\nШнобелевская премия по экономике отправилась в Новую Зеландию и Великобританию вместе с &Марком Ависом!&, &Сарой Форб!& и &Шилой Фергюсон!&. Группа занимается исследованиями индивидуальности брендов. В качестве материала для научной работы они взяли изображения камней. Результаты экспериментов показали, что камень G больше всего соответствует трендам и является самым гламурным, камень Н был признан самым сентиментальным, а у камня I обнаружились все черты независимости.\\nMarketing Theory Белогривые лошадки и стрекозы на кладбищах\\n«Шнобеля» в области физики за схожие работы присудили двум международным коллективам ученых. Исследователей привлекли особенности зрения насекомых и преломление горизонтально поляризованного зрения. Первая группа обнаружила неожиданные преимущества у лошадей со светлым волосяным покровом. Да, признают ученые, у белых лошадей чаще развиваются злокачественные опухоли из-за повышенной чувствительности к ультрафиолету и им сложнее маскироваться, зато их меньше кусают слепни. Свет, отраженный от поверхности тел темных лошадок, больше привлекает кровососущих, выяснили они. \\nДругой научной группе пришлось обойти немало венгерских кладбищ, чтобы выяснить, почему туда так тянет стрекоз. Гладко отполированные поверхности надгробных плит отражают горизонтально поляризованный свет так же, как водная гладь, рассказали ученые. &Это!& и привлекает насекомых. В итоге стрекозы попадают в экологическую ловушку: им приходится полностью приспосабливаться к жизни на новой местности.\\nНаградили за скандал\\nПремию по химии присудили немецкому автомобильному концерну Volkswagen за великий обман. В 2015 году на весь мир прогремел «дизельгейт»: на машинах с дизельным топливом были установлены специальные устройства, способные занижать показания выбросов выхлопных газов в атмосферу. Концерн обманывал экологов в течение семи лет. \\nНемцы почесали за премией\\nНемецкие ученые &Кристоф Хельмчен!&, &Карина Палцер!&, &Томас Мюнте!&, &Шилке Андрес!& и &Андреас Шпренгер!& увезли Шнобелевскую премию по медицине. Приступая к научной работе, исследователи явно преследовали благие цели, а именно хотели помочь людям избавиться от назойливого зудящего чувства. Научная группа пыталась выяснить, можно ли уменьшить чувство зуда, к примеру, на правой стороне тела, если встать у зеркала и чесать слева. Исследователи установили, что если чесать не там, где чешется, можно действительно облегчить себе жизнь. Они предложили новый, альтернативный метод лечения – «зеркальное почесывание», который поможет избавиться от неприятных ощущений страдающим от очаговых заболеваний кожи. \\nЛжец, лжец \\nЛожь и обман задавали тренд двадцать шестой Шнобелевской премии. Международный коллектив психологов получил награду за исследование по итогам опроса тысячи лжецов. По словам авторов, это первая научная работа, анализирующая то, как врут люди разных возрастов. Ученые выясняли, как с возрастом (от 6 до 77 лет) меняется количество произнесенной на дню неправды и речевая техника обмана. Проведя исследование, психологи установили, что люди достаточно часто врут в детстве, пик достигается в подростковом возрасте, а уже в зрелом возрасте начинается снижение. \\nКак работу назовешь…\\nШнобелевскую премию мира присудили за одно лишь название научной статьи. В работе «О восприятии и распознавании псевдомудрой чуши» (\"On the reception and detection of pseudo-profound bullshit\") психологи описали, как на людей влияют высказывания, якобы преисполненные мыслью. Предварительно исследователи случайным образом составили «философские изречения» («Ты силен настолько, насколько силен твой следующий ход», «Посреди движения и хаоса сохраняй спокойствие внутри себя») и показали их 845 участникам. Психологи выяснили, что испытуемые не отличают псевдомудрые сентенции от действительно мотивирующих высказываний, так как они выставляли равные баллы для этих высказываний по шкале «глубина мысли». \\nТакже участников исследования попросили рассказать о своих верованиях, идеалах и жизненных установках. Оказалось, что на самом деле любители «глубокомысленных цитат» зачастую суеверны, не склонны к размышлениям о жизни и легко попадают под убеждения о всемирном заговоре.\\nЖиви как выдра. Ну или хотя бы как козел\\nПерсональные награды по биологии достались британцам &Чарльзу Фостеру!& и &Томасу Твейтсу!&, которые однажды решили уподобиться животным.\\nЧтобы понять, что на самом деле чувствует барсук, надо жить, как барсук, уверен &Фостер!&. Прихватив с собой восьмилетнего сынишку, англичанин отправился в лес жить в норе и питаться червями и кузнечиками. Как рассказывал &Фостер!&, спустя две недели барсучьей жизни его обоняние и слух стали более чуткими. Этого пытливому уму показалось мало, и экспериментатор решил примерить на себя шкуру выдры. &Фостер!& жил на берегах реки и ловил рыбу зубами. Также он перевоплощался в оленя, лису и птицу. Моменты жизни в лесу легли в основу его книги «Быть зверем». \\nИстория &Томаса Твейтса!& являет собой воплощение классического кафкианского сюжета в реальной жизни. Проснувшись однажды утром после беспокойного сна, &Твейтс!& обнаружил в себе козлиное начало. Смастерив костюм парнокопытного, он поселился в Альпах, где провел три дня в компании рогатых. Свой опыт позднее &Твейтс!& описал в книге «Человек-козел». Как признается автор, только после общения с козлами он понял, что значит быть настоящим человеком. \\n«Коллекционер»\\n«Шнобеля» по литературе (и, кажется, незаслуженно) вручили шведу &Фредрику Шебергу!& «за описание удовольствия от коллекционирования насекомых уже умерших, и насекомых, еще живущих» в книге «Ловушка для насекомых». Этот роман является первой частью автобиографической трилогии &Шеберга!& «Путь энтомолога». В «Ловушке для насекомых» автор описывает времена, когда он изучал жуков на отдаленном острове. Книга наполнена лирическими размышлениями о красоте окружающего мира и ходе времени. Когда «Ловушка для насекомых» вышла в свет, о ней сразу же положительно отозвался &Тумас Транстремер!&, нобелевский лауреат по литературе 2011 года.\\nЧто увидели ученые между ног \\nЯпонских ученых &Ацуки Хигасияма!& и &Кохей Адачи!& наградили за исследования в области перцептивных процессов. Ученые пытались определить, как изменяется восприятие предметов, если, наклонившись, смотреть на них между ног. Проведя серию экспериментов, исследователи пришли к поразительным выводам: если просунуть голову между ног и смотреть на какой-либо предмет, будет казаться, что его размер меньше, чем он есть на самом деле.\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for text in marked:\n",
    "    if 'Марком Ависом' in text:\n",
    "        print(marked.index(text))\n",
    "        \n",
    "marked.pop(166)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find names in marked text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\&[А-ЯЁа-яё\\-\\s]+!\\&')\n",
    "names_list = []\n",
    "for text in marked:\n",
    "    names = re.findall(pattern, text)\n",
    "    clean_names = [name.replace('&', '').replace('!', '') for name in names]\n",
    "    names_list.extend(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_pop = [51, 52, 54, 123 , 131, 151, 157, 185, 196, 381, 398, 461, 511, 600, 655, 664, 929,\n",
    "          982, 1210, 1236, 1261, 1334, 1340, 1401, 1408, 1503, 1511, 1527, 1582, 1638, 1656,\n",
    "         1670, 1704, 1706]\n",
    "for i in to_pop:\n",
    "    names_list.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('evaluation_names.txt', 'w') as fo:\n",
    "    for name in names_list:\n",
    "        fo.write(name+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sample texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:00<00:00, 1619.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Number of texts:  175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "marked_texts, file_names = read_dir(test_input)\n",
    "texts = [text.replace('&', '').replace('!', '') for text in marked_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Выдающие специалисты, обладающие бесспорным опытом в научных областях, поделились с читателями Geektimes своими короткими комментариями относительно перспектив различных профессий в области медицины.\\nИТ медик\\n\\nМажуга Александр Георгиевич\\nПодробнее о научной деятельности\\nПрофессия будет востребована, но в перспективе лет. \\nПрогресс в области современной медицинской химии и фармакологии обеспечивает создание новых классов препаратов для терапии патологий различной этиологии. \\nОбразование базового врача общего профиля не позволяет адекватно оценивать совместимость лекарственных препаратов и возможные эффекты связанные с их применением. Задача ИТ медика разработать информационное «облако», которое будет автоматизировано оценивать риски приема лекарственных препаратов. \\nДругое направление – это обслуживание диагностических комплексов, разработка методологий оценки результатов исследований и рекомендации по терапии, это и есть задача будущей ИТ медицины.\\nБиоэтик\\n\\nЧрезвычайно важное направление, активизация исследований в области применения клеточных технологий, платформ на основе стволовых клеток требует разработки и сопровождения специалистов в области биоэтике. Я бы не называл это отдельной профессией. Тут необходима нормативная база.\\nОператор медицинских роботов\\n\\nКрайне необходимо и востребовано.\\nГенетический консультант\\n\\nБудет очень востребовано. Уже сейчас есть центры, где не хватает специалистов. Это профессия врач-генетик.\\nАрхитектор медоборудования\\n\\nПрокошкин Сергей Дмитриевич\\nПодробнее о научной деятельности\\nПрофессия, безусловно, перспективна. Перспективный конечный продукт – имплантат, инструмент или элемент устройства медицинской техники который должен обеспечить функциональные возможности, недостижимые при использовании традиционных материалов и технологий. \\n\\nБезусловное требование к нему — сочетание биомеханической и биохимической совместимости с тканями и жидкостями тела, а также с функциональным поведением замещаемых или восстанавливаемых органов. Архитектор медоборудования должен обладать знаниями и умениями, отвечающими такой перспективе.\\nПрочитать подробнее про профессии будущеге можно на сайте атласа новых профессий\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.pop(8)\n",
    "texts.pop(166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names.pop(8)\n",
    "file_names.pop(166) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_output = '/home/nst/mount/data/linguistics_hse/popular-science-research/Tomita_Parser/tomita-parser/build/bin/sci_names_eval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 92/173 [00:00<00:00, 910.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:00<00:00, 848.19it/s]\n",
      "173it [00:00, 1218.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts:  173\n",
      "Number of paths: 173\n",
      "Writing to files...\n",
      "All done, Buddy!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'[А-ЯЁа-яё\\.\\-\\d]+')\n",
    "preprocessed = []\n",
    "print('Preprocessing files...')\n",
    "for text in tqdm(texts):\n",
    "    preproc_text = ' '.join(re.findall(pattern, text))\n",
    "    preprocessed.append(preproc_text)\n",
    "paths = [test_output + name for name in file_names]\n",
    "print('Number of texts: ', len(texts))\n",
    "print('Number of paths:', len(paths))\n",
    "print('Writing to files...')\n",
    "spit(preprocessed, paths)\n",
    "print('All done, Buddy!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER-PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bs4 as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = slurp('/home/nst/mount/data/linguistics_hse/popular-science-research/Tomita_Parser/tomita-parser/build/bin/evaluation.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_xml(xml_output):\n",
    "    \n",
    "    def divide_names(names:list):\n",
    "        names_found = []\n",
    "        for name in names:\n",
    "            if len(name.split()) > 3:\n",
    "                n_sep = name.split()\n",
    "                start_index = 0\n",
    "                for n in n_sep:\n",
    "                    while start_index != len(n_sep):\n",
    "                        name = n_sep[start_index] + ' ' + n_sep[start_index+1]\n",
    "                        start_index+=2\n",
    "                        names_found.append(name)\n",
    "            else:\n",
    "                names_found.append(name)\n",
    "        return names_found\n",
    "    \n",
    "    \n",
    "    xml = bs.BeautifulSoup(xml_output, 'lxml')\n",
    "    names = xml.find_all('name')\n",
    "    pattern = re.compile(r'val=\"([А-ЯЁ]+)\">')\n",
    "    names_ext = []\n",
    "    for name in names:\n",
    "        name = name.get('val')\n",
    "        names_ext.append(name)\n",
    "    names_ext = [name.title() for name in names_ext]\n",
    "    names_sep = divide_names(names_ext)\n",
    "    return names_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "683"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = parse_xml(output)\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true = slurp('/home/nst/mount/data/linguistics_hse/popular-science-research/Tomita_Parser/tomita-parser/build/bin/evaluation_names.txt')\n",
    "true = true.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15156695156695157\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for name in names:\n",
    "    if name in true:\n",
    "        pred.append(name)\n",
    "accuracy = len(pred)/len(true)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete common words and geoterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2 \n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from flashtext import KeywordProcessor\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_lemmas_list(input_path):\n",
    "    lemmas_list = []\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for file_name in files:\n",
    "            file_path = input_path + file_name\n",
    "            lemmas = slurp(file_path)\n",
    "            lemmas = re.findall(r'[а-яё]+', lemmas)\n",
    "            lemmas_list.extend(lemmas)\n",
    "    lemmas_list = list(set(lemmas_list))\n",
    "    return lemmas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common = '/home/nst/mount/data/linguistics_hse/popular-science-research/slovnik/'\n",
    "common_words = compile_lemmas_list(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmas_processor = KeywordProcessor()\n",
    "lemmas_processor.add_keywords_from_list(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = pd.read_csv('/home/nst/mount/data/linguistics_hse/popular-science-research/cities.csv', sep='\\t')\n",
    "countries = pd.read_csv('/home/nst/mount/data/linguistics_hse/popular-science-research/countries.csv', sep='\\t')\n",
    "geo = cities.москва + countries.россия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmas_geo = KeywordProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_common_words(names:list):\n",
    "    potential_names = []\n",
    "    \n",
    "    for name in names:\n",
    "        true_name = []\n",
    "        name = name.split()\n",
    "        for n in name:\n",
    "            n = n.lower()\n",
    "            lemma = morph.parse(n)[0].normal_form\n",
    "            if not lemmas_processor.extract_keywords(lemma) == [lemma]:\n",
    "                true_name.append(n.title())\n",
    "                final_name = ' '.join(true_name)\n",
    "                potential_names.append(final_name)\n",
    "    print('Deleted common words, current size:', len(potential_names))\n",
    "    return potential_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_accuracy(true:list, eval_list:list):\n",
    "    pred = []\n",
    "    for name in eval_list:\n",
    "        if name in true:\n",
    "            pred.append(name)\n",
    "    accuracy = len(pred)/len(true)\n",
    "    print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted common words, current size: 630\n",
      "Accuracy: 0.1492877492877493\n"
     ]
    }
   ],
   "source": [
    "names_clean = delete_common_words(names)\n",
    "count_accuracy(true, names_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
