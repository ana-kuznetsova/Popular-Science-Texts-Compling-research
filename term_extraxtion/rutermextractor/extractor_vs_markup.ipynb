{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.stem import *\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rutermextract import TermExtractor\n",
    "\n",
    "def get_term_candidates(file_path):\n",
    "    \n",
    "    with open(file_path) as fl:\n",
    "        try:\n",
    "            text = fl.read()\n",
    "        except:\n",
    "            print (\"Error: \" + file_path )\n",
    "    \n",
    "    terms = []\n",
    "    term_extractor = TermExtractor()\n",
    "\n",
    "    for term in term_extractor(text):\n",
    "        terms.append(term.normalized)\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_terms(file_path):\n",
    "    \n",
    "    with open(file_path) as fl:\n",
    "        try:\n",
    "            text = fl.read()\n",
    "        except:\n",
    "            print (\"Error: \" + file_path )\n",
    "    \n",
    "    text = text.lower()\n",
    "    reg_term = re.compile(r'&(.*?)!&')\n",
    "    \n",
    "    raw_terms = reg_term.findall(text)\n",
    "    \n",
    "    terms = []\n",
    "    \n",
    "    for term in raw_terms:\n",
    "        terms.append(term)\n",
    "    \n",
    "    return list(set(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "start_path = './terms_markup/Marked/'\n",
    "\n",
    "contexts = []\n",
    "extractor = []\n",
    "\n",
    "ready_df = pd.DataFrame()\n",
    "\n",
    "for path, dirs, files in os.walk(start_path):    \n",
    "    for fname in files:\n",
    "        if not fname.startswith('.'):\n",
    "            contexts.append(get_terms(start_path+fname))\n",
    "            extractor.append(get_term_candidates(start_path+fname))\n",
    "            #df = pd.DataFrame([[terms, candidates]], columns=['terms', 'candidates'])\n",
    "            #ready_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "m = Mystem()\n",
    "\n",
    "lem_terms = []\n",
    "term_list = []\n",
    "\n",
    "for terms in contexts:\n",
    "    for term in terms:\n",
    "        term_list.append(''.join(m.lemmatize(term)).replace('\\n', ''))\n",
    "    lem_terms.append(term_list)\n",
    "    term_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lem_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lem_candidates = []\n",
    "candidate_list = []\n",
    "\n",
    "for candidates in extractor:\n",
    "    for candidate in candidates:\n",
    "        candidate_list.append(''.join(m.lemmatize(candidate)).replace('\\n', ''))\n",
    "    lem_candidates.append(candidate_list)\n",
    "    candidate_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lem_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare = []\n",
    "diff = []\n",
    "\n",
    "for i in range(72):\n",
    "    for term in lem_terms[i]:\n",
    "        if term not in lem_candidates[i]:\n",
    "            diff.append(term)\n",
    "    compare.append(diff)\n",
    "    diff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['порог скорость', 'магнитный подушка', 'маглевый', 'маглевый', 'маглеть'], [], ['митохондриальный геном', 'человек протоореньякский культура', 'представитель протоориньякский культура', 'отсеквенировать'], [], [], ['экспоненциально', 'индексация данные'], ['зебра греветь', 'равнинный или горный зебра'], [], [], ['фрактальный размерность траектория', 'передний область височный доля', 'амплитуда их вызывать потенциал', 'система положительный подкрепление обучение', 'возбуждение центральный нервный система', 'электрический активность испытуемый', 'передний часть островковый кора', 'экспериментально наивный'], ['оксид титан и ниобий', 'аморфный', 'реакция конверсия углекислый газ', 'сильный взаимодействие металл-носитель', 'со', 'сн4', 'синтез со', 'проницаемый', 'н2'], [], ['система внутренний подкрепление', 'система внутренний подкрепление', 'кора большой полушарие'], ['поздний, но не средний плейстоцен'], ['интенсифицироваться'], [], ['лигнифицироваться'], ['проводящий нить', 'динамика цветовой изменение', 'волна разный спектр', 'углеродный нанотрубок', 'световой волна разный спектр'], [], ['коммерциализация интеллектуальный продукт'], ['струя вещество', 'струя ', 'световой год'], ['узел с большой вес'], [], ['либеральный историография '], [], [], [], ['ботнет', 'дейвайс'], ['инфляционный теория ранний вселенная', 'горячий большой взрыв', 'степенный закон', 'стадия большой взрыв'], [], ['полнота данные', 'полнота данные', 'инклюзивный'], ['матрицировать', 'понятийный и концептуальный аппарат', 'рефлективный', 'эмоциональный шизофрения', 'интериоризировать моральный кодекс', 'протокультурный', 'имплицировать', 'детерминировать'], ['бфр', 'ноо'], ['независимый и зависимый переменная', 'вещественный', 'феномен аналитический продолжение', 'дифференцировать'], ['переменный', 'bootstrap aggregation'], [], ['проецироваться'], [], ['резервуарный эффект&!. величина &резервуарный эффект', 'радиоуглеродный данные', 'доля радиоактивный углерод', 'прэ'], [], ['язык такуу', 'язык маори', 'носитель язык полинезийский группа', 'восточный-полинезийский'], ['распространение усилие в среда', 'изменение возмущение в грунт'], ['гетерогенный', 'дезинвестировать', 'религиозный-фундаменталистский', 'ксенофобский', 'гибридный'], ['двойной слепой плацебо-контролировать', 'антикоагулянтный (против свертывание кровь) препарат', 'тромбоз глубокий вена', 'активированный форма фактор десять', 'фактор хагеман', 'фактор ха', 'фактор ха', 'рандомизированный двойной слепой плацебо-контролируемый клинический исследование', 'поверхность внутренний выстилка сосуд'], ['детектор альбедо нейтрон'], [], ['реакция иммунный система', 'синтезировать днк', 'строго упорядочивать нуклеиновый кислота', 'снк'], [], [], [], ['утилизировать вещество'], ['сопротивление в цепь', 'магнитный поле', 'теория электромагнитный поле', 'магнитный поле', 'магнитный поле', 'магнитный поле'], [], [], [], ['военнопленный', 'военнопленный', 'эксгумировать', '«еврейский зондеркоманда»', 'апробироваться', 'окончательный решение еврейский вопрос', 'военнопленный', 'утилизироваться', 'применять в массовый порядок'], [], ['средний и внутренний ухо'], [], ['метод ипд', 'наноструктурирование металл и сплав', 'индекс хирша', 'технология увеличение индекс хирша', 'индекс хирша', 'туиха', 'доминирование наукометрический подход'], ['синтез фишер-тропша', 'nh4+', 'k2(pho3)', 'со', 'фосфит калий', 'с3н6n6', 'легировать', 'сh4', 'ближний инфракрасный, видимый и ультрафиолетовый диапазон', 'алкана с линейный и разветвлять и циклический структура'], [], [], ['руководитель по продажа', 'реформировать рынок', 'девайса', 'ключевой комплектующий'], ['деяние корыстно-насильственный', 'система уголовный репрессия'], [], ['редуцироваться'], [], ['исполнительный и эмоциональный центр головной мозг'], ['техника листовой золочение'], [], ['геном', 'трансплантация костный мозг', 'клеточный и генный терапия', 'модифицированный т-клетка', 'т-клетка', 'иммунный т-клетка', 'популяция специфический иммунный клетка', 'модифицированный донорский т-клетка', 'иммунный т-клетка']]\n"
     ]
    }
   ],
   "source": [
    "print((compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results=open(\"results.txt\",\"w\")\n",
    "\n",
    "for i in range(72):\n",
    "    if len(compare[i]) != 0:\n",
    "        results.write(str(compare[i]))\n",
    "        results.write(\"\\n\")\n",
    "        results.write(str(extractor[i]))\n",
    "        results.write(\"\\n\")\n",
    "        results.write('-----------------------')\n",
    "        results.write(\"\\n\")\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.Series(contexts, name = 'terms')\n",
    "df2 = pd.Series(extractor, name = 'candidates')\n",
    "\n",
    "#compare = pd.concat([df1, df2], axis = 1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[порог скорости, магнитной подушке, магнитная ...</td>\n",
       "      <td>[час, скорость, поезд, магнитная подушка, преф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[бихевиористского направления, теория штерна, ...</td>\n",
       "      <td>[человек, слово, ребёнок, заяц, вид, схожая ра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[homo sapiens, геном, митохондриального генома...</td>\n",
       "      <td>[усть-ишимский человек, современное тип, прото...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[пропофол, анестезию, неврология, анестезии, ф...</td>\n",
       "      <td>[анестезия, анестезиология, анестезиологи, кли...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>[карпинский, чай, академия, российская академи...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               terms  \\\n",
       "0  [порог скорости, магнитной подушке, магнитная ...   \n",
       "1  [бихевиористского направления, теория штерна, ...   \n",
       "2  [homo sapiens, геном, митохондриального генома...   \n",
       "3  [пропофол, анестезию, неврология, анестезии, ф...   \n",
       "4                                                 []   \n",
       "\n",
       "                                          candidates  \n",
       "0  [час, скорость, поезд, магнитная подушка, преф...  \n",
       "1  [человек, слово, ребёнок, заяц, вид, схожая ра...  \n",
       "2  [усть-ишимский человек, современное тип, прото...  \n",
       "3  [анестезия, анестезиология, анестезиологи, кли...  \n",
       "4  [карпинский, чай, академия, российская академи...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare.to_csv('terms vs extractor', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
